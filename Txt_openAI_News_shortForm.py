import urllib.request
import urllib.parse
import json
import openai
import time
import html
import os
import requests
import shutil
import re
from dotenv import load_dotenv
from moviepy.editor import (
    ImageClip,
    TextClip,
    CompositeVideoClip,
    concatenate_videoclips,
    AudioFileClip,
)
import moviepy.config as mpy_config
from PIL import Image, ImageDraw, ImageFont
import numpy as np

load_dotenv()

os.environ["IMAGEMAGICK_BINARY"] = (
    r"C:\Program Files\ImageMagick-7.1.1-Q16-HDRI\magick.exe"
)
mpy_config.change_settings(
    {"IMAGEMAGICK_BINARY": r"C:\Program Files\ImageMagick-7.1.1-Q16-HDRI\magick.exe"}
)


### form_data í´ë” ë‚´ ëª¨ë“  íŒŒì¼ ì‚­ì œ (ì—†ìœ¼ë©´ ìƒì„±)
# FORM_DATA_DIR = "form_data"
# if os.path.exists(FORM_DATA_DIR):
#     for filename in os.listdir(FORM_DATA_DIR):
#         file_path = os.path.join(FORM_DATA_DIR, filename)
#         try:
#             if os.path.isfile(file_path) or os.path.islink(file_path):
#                 os.unlink(file_path)
#             elif os.path.isdir(file_path):
#                 shutil.rmtree(file_path)
#         except Exception as e:
#             print(f"Failed to delete {file_path}. Reason: {e}")
# else:
#     os.makedirs(FORM_DATA_DIR)

# ğŸ”¹ OpenAI GPT-4 API ì„¤ì •
client = openai.OpenAI(api_key=os.getenv("openAiKey"))

# ğŸ”¹ ë„¤ì´ë²„ ê²€ìƒ‰ API ì„¤ì •
client_id = os.getenv("naverId")
client_secret = os.getenv("naverSecret")

# ğŸ”¹ ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰ í‚¤ì›Œë“œ
categories = {
    "ì •ì¹˜": "ì •ì¹˜ ë‰´ìŠ¤",
    "ê²½ì œ": "ê²½ì œ ë‰´ìŠ¤",
    "ì‚¬íšŒ": "ì‚¬íšŒ ë‰´ìŠ¤",
    "ìƒí™œ/ë¬¸í™”": "ìƒí™œ ë¬¸í™” ë‰´ìŠ¤",
    "IT/ê³¼í•™": "IT ê³¼í•™ ë‰´ìŠ¤",
    "ì„¸ê³„": "êµ­ì œ ë‰´ìŠ¤",
}

# ğŸ”¹ "ì†ë³´" ê²€ìƒ‰ ì¶”ê°€
categories["ì†ë³´"] = "ì†ë³´ ë‰´ìŠ¤"

# ğŸ”¹ ë‰´ìŠ¤ ì €ì¥ ë¦¬ìŠ¤íŠ¸
summarized_news = {}

### ë‰´ìŠ¤ ê²€ìƒ‰
for category, keyword in categories.items():
    print(f"\nğŸ“¡ [{category}] ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘...")

    encText = urllib.parse.quote(keyword)
    url = f"https://openapi.naver.com/v1/search/news.json?query={encText}&display=5&sort=date"  # display 5

    request = urllib.request.Request(url)
    request.add_header("X-Naver-Client-Id", client_id)
    request.add_header("X-Naver-Client-Secret", client_secret)

    try:
        response = urllib.request.urlopen(request)
        rescode = response.getcode()

        if rescode == 200:
            response_body = response.read()
            news_data = json.loads(response_body.decode("utf-8"))

            if "items" not in news_data or not news_data["items"]:
                print(f"âš ï¸ '{category}' ì¹´í…Œê³ ë¦¬ì—ì„œ ê²€ìƒ‰ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue

            # ğŸ”¹ ëŒ€í‘œ ë‰´ìŠ¤ 1ê°œë¡œ ì„ íƒ // ì¤‘ë³µë˜ì§€ ì•ŠëŠ” ë‰´ìŠ¤ 3ê°œ ì„ íƒ
            selected_news = []
            seen_titles = set()

            for news in news_data["items"]:
                title = html.unescape(
                    news["title"].replace("<b>", "").replace("</b>", "").strip()
                )
                link = news["link"]
                description = html.unescape(
                    news["description"].replace("<b>", "").replace("</b>", "").strip()
                )

                if title not in seen_titles and len(selected_news) < 1:
                    selected_news.append(
                        {"title": title, "link": link, "description": description}
                    )
                    seen_titles.add(title)

                if len(selected_news) >= 1:
                    break

            # ğŸ”¹ ì„ íƒëœ ë‰´ìŠ¤ ìš”ì•½
            news_list = []

            for news in selected_news:
                prompt = (
                    f"ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì§§ê³  ëª…í™•í•˜ê²Œ ìš”ì•½í•´ì¤˜:\n\n{news['description']}"
                )
                try:
                    response = client.chat.completions.create(
                        model="gpt-4",
                        messages=[
                            {
                                "role": "system",
                                "content": "ë‹¹ì‹ ì€ ë‰´ìŠ¤ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.",
                            },
                            {"role": "user", "content": prompt},
                        ],
                        max_tokens=150,
                        temperature=0.5,
                    )
                    summary = html.unescape(response.choices[0].message.content.strip())
                except Exception as gpt_error:
                    summary = f"[ì˜¤ë¥˜] GPT ìš”ì•½ ì‹¤íŒ¨: {gpt_error}"

                # ğŸ”¹ ìµœì¢… ê²°ê³¼ ì €ì¥
                news_list.append(
                    {"title": news["title"], "link": news["link"], "summary": summary}
                )

                # ğŸ”¹ API í˜¸ì¶œ ê°„ ë”œë ˆì´ ì¶”ê°€
                time.sleep(1)

            summarized_news[category] = news_list

        else:
            print(f"âŒ [ì˜¤ë¥˜] '{category}' ë‰´ìŠ¤ ìš”ì²­ ì‹¤íŒ¨ (ì½”ë“œ: {rescode})")

    except urllib.error.URLError as e:
        print(f"âŒ [ì˜¤ë¥˜] '{category}' ë‰´ìŠ¤ ìš”ì²­ ì‹¤íŒ¨: {e.reason}")
        continue

# ğŸ”¹ ê²°ê³¼ ì¶œë ¥
for category, articles in summarized_news.items():
    print(f"\nğŸ“Œ [{category}]")
    for article in articles:
        print(f"ğŸ”¹ ì œëª©: {article['title']}")
        print(f"ğŸ“ ìš”ì•½: {article['summary']}")
        print(f"ğŸ”— ë§í¬: {article['link']}\n")


### ê²°ê³¼ë¬¼ ì˜ì–´ë¡œ ë²ˆì—­ ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°
def translate_and_clean(text):
    """
    ì£¼ì–´ì§„ textë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•˜ê³ , ì•ŒíŒŒë²³, ìˆ«ì, ê³µë°±ì„ ì œì™¸í•œ ëª¨ë“  ë¬¸ìë¥¼ ì œê±°í•©ë‹ˆë‹¤.
    """
    prompt = f"Translate the following text to English and remove all special characters (keep only letters, numbers, and spaces):\n\n{text}"
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=300,
            temperature=0.0,
        )
        translated = response.choices[0].message.content.strip()
    except Exception as e:
        print(f"Translation error: {e}")
        translated = text  # ì—ëŸ¬ ë°œìƒ ì‹œ ì›ë³¸ ì‚¬ìš©

    # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ íŠ¹ìˆ˜ë¬¸ì ì œê±° (ì•ŒíŒŒë²³, ìˆ«ì, ê³µë°±ë§Œ ë‚¨ê¹€)
    cleaned = re.sub(r"[^A-Za-z0-9\s]", "", translated)
    return cleaned


text_clips = []

### í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
# test_text = "Test : Hello World !!!"

# # í…ìŠ¤íŠ¸ ìë§‰ í´ë¦½ ìƒì„± (ë‰´ìŠ¤ ì œëª©ê³¼ ìš”ì•½)
# # text = f"{article['title']}\n{article['summary']}"
# clip = TextClip(
#     # text,
#     test_text,
#     fontsize=30,
#     color="white",
#     bg_color="black",
#     size=(1280, 720),  # ì›í•˜ëŠ” í•´ìƒë„ ì§€ì •
#     method="caption",  # ìë™ ì¤„ë°”ê¿ˆ
#     font="Malgun Gothic",
# ).set_duration(4)
# text_clips.append(clip)


for category, articles in summarized_news.items():
    # í…ìŠ¤íŠ¸ ìë§‰ í´ë¦½ ìƒì„± (ë‰´ìŠ¤ ì œëª©ê³¼ ìš”ì•½)
    original_text = f"{article['title']}\n{article['summary']}"
    news_text = translate_and_clean(original_text)
    print("Translated and cleaned news_text:")
    print(news_text)

    clip = TextClip(
        news_text,
        fontsize=30,
        color="white",
        bg_color="black",
        size=(1280, 720),  # ì›í•˜ëŠ” í•´ìƒë„ ì§€ì •
        method="caption",  # ìë™ ì¤„ë°”ê¿ˆ
        font="Malgun Gothic",
    ).set_duration(4)
    text_clips.append(clip)

# ê¸°ì¡´ ê²°ê³¼ë¬¼ ì‚­ì œ
if os.path.exists("news_summary.mp4"):
    os.remove("news_summary.mp4")

# ëª¨ë“  í´ë¦½ì„ ì—°ê²°í•´ ìµœì¢… ì˜ìƒ ìƒì„± (fps 24, ìœ íŠœë¸Œ ìˆí¼ì— ë§ê²Œ ì´ ê¸¸ì´ ì¡°ì ˆ)
if text_clips:
    final_video = concatenate_videoclips(text_clips)
    # ì˜ìƒ ê¸¸ì´ê°€ 30ì´ˆë¥¼ ì´ˆê³¼í•˜ë©´ 30ì´ˆë¡œ ì˜ë¼ì¤Œ
    if final_video.duration > 27:
        final_video = final_video.subclip(0, 27)
    # BGM ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ ë° ì˜ìƒ ê¸¸ì´ì— ë§ê²Œ ìë¥´ê¸°
    bgm_clip = AudioFileClip("News.mp3").subclip(0, final_video.duration)
    # ì˜¤ë””ì˜¤ ë³¼ë¥¨ ì¡°ì ˆì´ í•„ìš”í•˜ë©´ .volumex(0.5) ë“±ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ
    final_video = final_video.set_audio(bgm_clip)

    final_video.write_videofile("news_summary.mp4", fps=24)
else:
    print("í‘œì‹œí•  ë‰´ìŠ¤ ìš”ì•½ì´ ì—†ìŠµë‹ˆë‹¤.")
